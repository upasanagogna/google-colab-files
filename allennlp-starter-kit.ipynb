{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"allennlp-starter-kit.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"1W7xIrjNhcJ8"},"source":["# Simple baseline with AllenNlP\n","\n","I haven't seen anyone try to use AllenNLP for a kaggle competition before, so I wrote this kernel to show how it could be done.  \n","AllenNLP abstracts away most of the boilerplate code like training loops, loading pretrained embeddings, and keeping track of experiments which lets you write a lot less code. It also lets you change model architectures and hyperparameters by  creating new experiments entirely from configuration files instead of changing the code for each new experiment."]},{"cell_type":"markdown","metadata":{"id":"DOUlVcC5hcJ-"},"source":["### Install AllenNLP from dataset"]},{"cell_type":"code","metadata":{"id":"cBK7dAbDhzkL","executionInfo":{"status":"ok","timestamp":1604917427855,"user_tz":-330,"elapsed":57980,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"cf279d35-f233-4cc5-c8db-414f5776cd12","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install allennlp\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting allennlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/14/f0f9dd1ce012e7723742821b95b33dd9bdc53befe209600608bc7be1f650/allennlp-1.2.0-py3-none-any.whl (498kB)\n","\u001b[K     |████████████████████████████████| 501kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.41.1)\n","Collecting tensorboardX>=1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 16.6MB/s \n","\u001b[?25hCollecting boto3<2.0,>=1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/54/099a2ea5d4b2d5931a26f280a7585f613b1fafaac9189e489a9e25004a01/boto3-1.16.13-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 15.5MB/s \n","\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n","Collecting jsonpickle\n","  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n","Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.12)\n","Collecting overrides==3.1.0\n","  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n","Requirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.7.0+cu101)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n","Collecting transformers<3.5,>=3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 17.8MB/s \n","\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/70/ed1ba808a87d896b9f4d25400dda54e089ca7a97e87cee620b3744997c89/jsonnet-0.16.0.tar.gz (256kB)\n","\u001b[K     |████████████████████████████████| 266kB 31.0MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.7)\n","Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.12.4)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.3MB/s \n","\u001b[?25hCollecting botocore<1.20.0,>=1.19.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 22.3MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.10)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (50.3.2)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (20.2.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 30.5MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp) (20.4)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 44.6MB/s \n","\u001b[?25hCollecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 49.1MB/s \n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.8.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (2.0.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (3.0.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.3)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp) (1.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.17.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3<2.0,>=1.14->allennlp) (2.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp) (3.4.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.5,>=3.1->allennlp) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.5,>=3.1->allennlp) (2.4.7)\n","Building wheels for collected packages: overrides, jsonnet, sacremoses\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=69bb1a6291eee6bdc8488b1e3c2b1fd8512f187ac19eb78c208abbc0176a61f3\n","  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jsonnet: filename=jsonnet-0.16.0-cp36-cp36m-linux_x86_64.whl size=3321601 sha256=8f2fd77d4040af7262d8c47fc16a6a1c62a2dc3ab73681d1c40c3ac57683607d\n","  Stored in directory: /root/.cache/pip/wheels/64/a9/43/bc5e0463deeec89dfca928a2a64595f1bdb520c891f6fbd09c\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=481039a9cead5f7c077adae977adc81052539b2d497587fb6dfee06743072c2c\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built overrides jsonnet sacremoses\n","\u001b[31mERROR: botocore 1.19.13 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboardX, jmespath, botocore, s3transfer, boto3, jsonpickle, overrides, sacremoses, sentencepiece, tokenizers, transformers, jsonnet, allennlp\n","Successfully installed allennlp-1.2.0 boto3-1.16.13 botocore-1.19.13 jmespath-0.10.0 jsonnet-0.16.0 jsonpickle-1.4.1 overrides-3.1.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tensorboardX-2.1 tokenizers-0.9.2 transformers-3.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m-iwoRGZh_gh","executionInfo":{"status":"ok","timestamp":1604917434404,"user_tz":-330,"elapsed":3423,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"4001a37a-26e3-4a5b-f215-960674d43eb4","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install overrides"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J7XZEtACiND-","executionInfo":{"status":"ok","timestamp":1604917462865,"user_tz":-330,"elapsed":4819,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"9c713ee4-d44a-460c-8dfa-e9f346a64f22","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install mlcrate "],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting mlcrate\n","  Downloading https://files.pythonhosted.org/packages/78/7d/7a58b3eeae81efb695806eadf11e9290c6223ce1d3cf3a16b2a374901275/mlcrate-0.2.0-py3-none-any.whl\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlcrate) (1.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlcrate) (1.18.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from mlcrate) (4.41.1)\n","Collecting pathos\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/9e/0100b1d500851fc8e093da5463ca38e013c86ea0855e7c510ca0d3e1f7c1/pathos-0.2.7-py2.py3-none-any.whl (81kB)\n","\u001b[K     |████████████████████████████████| 81kB 3.6MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlcrate) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->mlcrate) (2.8.1)\n","Collecting multiprocess>=0.70.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/dc/426a82723c460cfab653ebb717590103d6e38cebc9d1f599b0898915ac1d/multiprocess-0.70.11.1-py36-none-any.whl (101kB)\n","\u001b[K     |████████████████████████████████| 102kB 5.2MB/s \n","\u001b[?25hCollecting ppft>=1.6.6.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/7b/e63dcf1f9b5ecd37691ee8a7029f71ddb7cafab780a60e312d913afc0f29/ppft-1.6.6.3-py3-none-any.whl (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: dill>=0.3.3 in /usr/local/lib/python3.6/dist-packages (from pathos->mlcrate) (0.3.3)\n","Collecting pox>=0.2.9\n","  Downloading https://files.pythonhosted.org/packages/6b/06/600e1b1103336ce94cf01e63a6c7b134f0edccf59bbf99189c975e2f257e/pox-0.2.9-py2.py3-none-any.whl\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->mlcrate) (1.15.0)\n","Installing collected packages: multiprocess, ppft, pox, pathos, mlcrate\n","  Found existing installation: multiprocess 0.70.10\n","    Uninstalling multiprocess-0.70.10:\n","      Successfully uninstalled multiprocess-0.70.10\n","Successfully installed mlcrate-0.2.0 multiprocess-0.70.11.1 pathos-0.2.7 pox-0.2.9 ppft-1.6.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0pIDbG19hcKF","executionInfo":{"status":"ok","timestamp":1604918082829,"user_tz":-330,"elapsed":1771,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"4f03da75-c2f8-49d6-d77f-7ebc08296901","colab":{"base_uri":"https://localhost:8080/"}},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","FOLD = 0\n","\n","import os\n","import sys\n","import random\n","import glob\n","import gc\n","import logging\n","import requests\n","import re\n","\n","from typing import Dict, Tuple, List\n","from collections import OrderedDict\n","from overrides import overrides\n","from time import sleep\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","\n","import mlcrate as mlc\n","\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","\n","import torchvision\n","\n","import allennlp\n","\n","from allennlp.common import Registrable, Params\n","from allennlp.common.util import START_SYMBOL, END_SYMBOL, JsonDict\n","\n","from allennlp.data import DatasetReader, Instance\n","from allennlp.data.fields import ArrayField, TextField\n","#from allennlp.data.iterators import BucketIterator, MultiprocessIterator\n","from allennlp.data.token_indexers import SingleIdTokenIndexer\n","from allennlp.data.tokenizers import Token, CharacterTokenizer\n","from allennlp.data.vocabulary import Vocabulary\n","\n","from allennlp.models import Model\n","\n","from allennlp.modules.token_embedders import Embedding\n","from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper # MIGHT USE FOR ABSTRACTION\n","\n","from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n","from allennlp.nn.beam_search import BeamSearch\n","\n","from allennlp.training.metrics import F1Measure, BLEU\n","from allennlp.training import Trainer\n","\n","sys.path.insert(0, './math_handwriting_recognition')\n","\n","logger = logging.getLogger()\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J2PAHAIkhcKJ"},"source":["## Load and split data"]},{"cell_type":"code","metadata":{"id":"caKTyn1KhcKK","executionInfo":{"status":"error","timestamp":1604918107225,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"aa2c3d9b-df19-47d7-9ff7-895681781015","colab":{"base_uri":"https://localhost:8080/","height":450}},"source":["train = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n","test = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv')\n","sample_submission = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv')"],"execution_count":8,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-4fe494440183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv'"]}]},{"cell_type":"code","metadata":{"id":"cXuWQ0FPhcKN"},"source":["!mkdir jigsaw\n","!touch jigsaw/__init__.py\n","\n","# Get a 5 fold cv\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","train_idx, val_idx = list(kfold.split(train))[0]\n","train_df, val_df = train.iloc[train_idx].reset_index(), train.iloc[val_idx].reset_index()\n","train_df.to_csv('train.csv')\n","val_df.to_csv('val.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbtYfuVchcKR"},"source":["## Dataset reader"]},{"cell_type":"code","metadata":{"id":"PFGIvkZIhcKR","outputId":"58cfda7d-b24a-43ac-939f-2db3b145f65b"},"source":["%%writefile jigsaw/dataset.py\n","import os\n","import random\n","from typing import Dict, Tuple, List\n","from overrides import overrides\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","\n","import spacy\n","\n","import allennlp\n","\n","from allennlp.common.util import START_SYMBOL, END_SYMBOL, get_spacy_model\n","\n","from allennlp.data import DatasetReader, Instance\n","from allennlp.data.fields import ArrayField, TextField, MetadataField, LabelField\n","from allennlp.data.token_indexers import SingleIdTokenIndexer\n","from allennlp.data.tokenizers import Token, Tokenizer, CharacterTokenizer, WordTokenizer\n","\n","@Tokenizer.register(\"simple\")\n","class LatexTokenizer(Tokenizer):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","    def _tokenize(self, text):\n","        return [Token(token) for token in text.split()]\n","\n","    @overrides\n","    def tokenize(self, text: str) -> List[Token]:\n","        tokens = self._tokenize(text)\n","\n","        return tokens\n","\n","@DatasetReader.register('jigsaw')\n","class JigsawDatasetReader(DatasetReader):\n","    def __init__(self, root_path: str, tokenizer: Tokenizer, lazy: bool = True, subset: bool = False) -> None:\n","        super().__init__(lazy)\n","        \n","        self.root_path = root_path\n","        self.subset = subset\n","        \n","        self._tokenizer = tokenizer\n","        self._token_indexer = {\"tokens\": SingleIdTokenIndexer()}\n","\n","    @overrides\n","    def _read(self, file: str):\n","        df = pd.read_csv(os.path.join(self.root_path, file))\n","\n","        if self.subset:\n","            df = df.loc[:16]\n","\n","        for _, row in df.iterrows():\n","            idx = row['id']\n","            comment_text = row['comment_text']\n","            \n","            if 'target' in df.columns:\n","                target = int(row['target'] > 0.5)\n","                yield self.text_to_instance(idx, comment_text, target)\n","            else:\n","                yield self.text_to_instance(idx, comment_text)\n","            \n","    @overrides\n","    def text_to_instance(self, idx: str, comment_text: str, target: float = None) -> Instance:\n","        comment_text = self._tokenizer.tokenize(comment_text)\n","        \n","        fields = {}\n","        fields['idx'] = MetadataField({'idx': idx})\n","        fields['comment_text'] = TextField(comment_text, self._token_indexer)\n","\n","        if target is not None:\n","            fields['target'] = LabelField(target, skip_indexing=True)\n","        \n","        return Instance(fields)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing jigsaw/dataset.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1QFcnbP4hcKV"},"source":["## Simple LSTM baseline model"]},{"cell_type":"code","metadata":{"id":"zAzcf_s0hcKV","outputId":"065e3fc0-a1a3-4183-e702-8dd93abc660d"},"source":[" %%writefile jigsaw/model.py\n","import os\n","import random\n","from typing import Dict, Tuple\n","from overrides import overrides\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","\n","import allennlp\n","\n","from allennlp.common import Registrable, Params\n","from allennlp.common.util import START_SYMBOL, END_SYMBOL\n","\n","from allennlp.data.vocabulary import Vocabulary\n","\n","from allennlp.models import Model\n","\n","from allennlp.modules import FeedForward\n","from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n","from allennlp.modules.token_embedders import Embedding\n","from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n","\n","from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n","\n","from allennlp.nn.beam_search import BeamSearch\n","\n","from allennlp.training.metrics import F1Measure, BLEU, Auc, BooleanAccuracy\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","@Model.register('baseline')\n","class Baseline(Model):\n","    def __init__(self, embeddings: TextFieldEmbedder, encoder: Seq2VecEncoder, classifier: FeedForward, vocab: Vocabulary) -> None:\n","        super().__init__(vocab)\n","\n","        self.embedding = embeddings\n","        \n","        self.encoder = encoder\n","        self.classifier = classifier\n","        \n","        self.loss = nn.BCEWithLogitsLoss()\n","        self.accuracy = BooleanAccuracy()\n","        \n","    @overrides\n","    def forward(self, idx: Dict[str, torch.Tensor], comment_text: Dict[str, torch.Tensor], target: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n","        mask = get_text_field_mask(comment_text)\n","\n","        x = self.embedding(comment_text)\n","        x = self.encoder(x, mask)\n","        x = self.classifier(x).view(-1)\n","        \n","        logits = torch.sigmoid(x)\n","                \n","        out = {'idx': idx, 'pred': logits}\n","\n","        if target is not None:\n","            if not self.training:\n","                self.accuracy((logits > 0.5).int(), target.int())\n","\n","            out['loss'] = self.loss(x, target.float())\n","\n","        return out\n","\n","    @overrides\n","    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n","        if not self.training:\n","            metrics = {\n","                \"accuracy\": self.accuracy.get_metric(reset)\n","            }\n","        else:\n","            metrics = {}\n","        \n","        return metrics"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing jigsaw/model.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8EN3y_SThcKZ"},"source":["## Predictor to get test predictions"]},{"cell_type":"code","metadata":{"id":"yfWtta4mhcKa","outputId":"1798da14-8731-47b3-ce56-d856ce2bfbc4"},"source":["%%writefile jigsaw/predictor.py\n","import os\n","import random\n","from typing import Dict, Tuple, List\n","from overrides import overrides\n","import json\n","\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import skimage\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","\n","import mlcrate as mlc\n","\n","import allennlp\n","\n","from allennlp.common import Registrable, Params\n","from allennlp.common.util import START_SYMBOL, END_SYMBOL, JsonDict, sanitize\n","\n","from allennlp.data import DatasetReader, Instance\n","from allennlp.data.vocabulary import Vocabulary\n","\n","from allennlp.models import Model\n","\n","from allennlp.predictors.predictor import Predictor\n","\n","from allennlp.modules.token_embedders import Embedding\n","from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n","from allennlp.nn.beam_search import BeamSearch\n","\n","from allennlp.training.metrics import F1Measure, BLEU\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","@Predictor.register('jigsaw')\n","class JigsawPredictor(Predictor):\n","    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n","        super().__init__(model, dataset_reader)\n","        \n","    def dump_line(self, outputs: JsonDict) -> str:\n","        pred = str(outputs['pred'])\n","\n","        return f'{pred}\\n'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing jigsaw/predictor.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zESNZtAqhcKe"},"source":["## Config file to set up experiments without changing the code"]},{"cell_type":"code","metadata":{"id":"24K1GdG6hcKf","outputId":"da8754b9-5a38-4c7c-939e-04bca1b08fc8"},"source":["%%writefile config.json\n","{\n","    \"dataset_reader\": {\n","        \"type\": \"jigsaw\",\n","        \"root_path\": \"./\",\n","        \"lazy\": true,\n","        \"subset\": false,\n","        \"tokenizer\": {\n","            \"type\": \"simple\"\n","        }\n","    },\n","    \"train_data_path\": \"train.csv\",\n","    \"validation_data_path\": \"val.csv\",\n","    \"model\": {\n","        \"type\": \"baseline\",\n","        \"embeddings\": {\n","          \"tokens\": {\n","            \"type\": \"embedding\",\n","            \"pretrained_file\": \"../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt\",\n","            \"embedding_dim\": 300,\n","            \"trainable\": false\n","          }\n","        },\n","        'encoder': {\n","            'type': 'lstm',\n","            'bidirectional': false,\n","            'input_size': 300,\n","            'hidden_size': 64,\n","            'num_layers': 1\n","        },\n","        'classifier': {\n","            'input_dim': 64,\n","            'num_layers': 1,\n","            'hidden_dims': 1,\n","            'activations': 'linear' # sigmoid activation is applied separately\n","        }\n","    },\n","    \"iterator\": {\n","        \"type\": \"bucket\",\n","        \"sorting_keys\":[[\"comment_text\", \"num_tokens\"]],\n","        \"batch_size\": 512\n","    },\n","    \"trainer\": {\n","        \"num_epochs\": 4,\n","        \"cuda_device\": 0,\n","        \"optimizer\": {\n","            \"type\": \"adam\",\n","            \"lr\": 0.001\n","        },\n","        \"grad_clipping\": 5,\n","        \"learning_rate_scheduler\": {\n","            \"type\": \"reduce_on_plateau\",\n","            \"factor\": 0.5,\n","            \"patience\": 5\n","        },\n","        \"num_serialized_models_to_keep\": 1,\n","        \"summary_interval\": 10,\n","        \"histogram_interval\": 100,\n","        \"should_log_parameter_statistics\": true,\n","        \"should_log_learning_rate\": true\n","    },\n","    'vocabulary': {\n","        'max_vocab_size': 100000,\n","#         \"directory_path\": \"./vocabulary\"\n","    }\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing config.json\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ulNt67f5hcKj"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"ImxwAmFghcKk","outputId":"9f123caa-71af-47d3-dc94-555a9dcefd6c"},"source":["!allennlp train config.json -s ./logs --include-package jigsaw\n","# !rm -rf logs/*"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 20:45:08,618 - INFO - allennlp.common.params - random_seed = 13370\r\n","2019-04-06 20:45:08,618 - INFO - allennlp.common.params - numpy_seed = 1337\r\n","2019-04-06 20:45:08,618 - INFO - allennlp.common.params - pytorch_seed = 133\r\n","2019-04-06 20:45:08,619 - INFO - allennlp.common.checks - Pytorch version: 1.0.1.post2\r\n","2019-04-06 20:45:08,620 - INFO - allennlp.common.params - evaluate_on_test = False\r\n","2019-04-06 20:45:08,620 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.params - dataset_reader.type = jigsaw\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.params - dataset_reader.root_path = ./\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = simple\r\n","2019-04-06 20:45:08,621 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - dataset_reader.lazy = True\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - dataset_reader.subset = False\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - validation_dataset_reader = None\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - train_data_path = train.csv\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.training.util - Reading training data from train.csv\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - validation_data_path = val.csv\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.training.util - Reading validation data from val.csv\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - test_data_path = None\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.training.trainer - From dataset instances, train, validation will be considered for vocabulary creation.\r\n","2019-04-06 20:45:08,622 - INFO - allennlp.common.params - vocabulary.type = None\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.extend = False\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.directory_path = None\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.min_count = None\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.max_vocab_size = 100000\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\r\n","2019-04-06 20:45:08,623 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\r\n","1804874it [06:47, 4424.94it/s]\r\n","2019-04-06 20:51:57,458 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'pretrained_file': '../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt', 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 20:51:57,459 - INFO - allennlp.common.params - model.type = baseline\r\n","2019-04-06 20:51:57,459 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'pretrained_file': '../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt', 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 20:51:57,459 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'pretrained_file': '../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt', 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 20:51:57,459 - INFO - allennlp.common.params - model.embeddings.type = basic\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.params - model.embeddings.embedder_to_indexer_map = None\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.params - model.embeddings.allow_unmatched_keys = False\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.params - model.embeddings.token_embedders = None\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'pretrained_file': '../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt', 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.params - model.embeddings.tokens.type = embedding\r\n","2019-04-06 20:51:57,460 - INFO - allennlp.common.params - model.embeddings.tokens.num_embeddings = None\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.vocab_namespace = tokens\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.embedding_dim = 300\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.pretrained_file = ../input/quoratextemb/embeddings/glove.840B.300d/glove.840B.300d.txt\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.projection_dim = None\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.trainable = False\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.padding_index = None\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.max_norm = None\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.norm_type = 2.0\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.scale_grad_by_freq = False\r\n","2019-04-06 20:51:57,461 - INFO - allennlp.common.params - model.embeddings.tokens.sparse = False\r\n","2019-04-06 20:51:57,479 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file\r\n","2196017it [00:13, 159852.87it/s]\r\n","2019-04-06 20:52:11,315 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer\r\n","2019-04-06 20:52:12,107 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 53433 out of 100002 tokens\r\n","2019-04-06 20:52:12,129 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 20:52:12,129 - INFO - allennlp.common.params - model.encoder.type = lstm\r\n","2019-04-06 20:52:12,129 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - model.encoder.bidirectional = False\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - model.encoder.hidden_size = 64\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - model.encoder.input_size = 300\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - model.encoder.num_layers = 1\r\n","2019-04-06 20:52:12,130 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 20:52:12,135 - INFO - allennlp.common.params - model.classifier.input_dim = 64\r\n","2019-04-06 20:52:12,135 - INFO - allennlp.common.params - model.classifier.num_layers = 1\r\n","2019-04-06 20:52:12,135 - INFO - allennlp.common.params - model.classifier.hidden_dims = 1\r\n","2019-04-06 20:52:12,135 - INFO - allennlp.common.params - model.classifier.activations = linear\r\n","2019-04-06 20:52:12,135 - INFO - allennlp.common.params - model.classifier.dropout = 0.0\r\n","2019-04-06 20:52:12,416 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']], 'type': 'bucket'} and extras set()\r\n","2019-04-06 20:52:12,416 - INFO - allennlp.common.params - iterator.type = bucket\r\n","2019-04-06 20:52:12,416 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']]} and extras set()\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.sorting_keys = [['comment_text', 'num_tokens']]\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.batch_size = 512\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.cache_instances = False\r\n","2019-04-06 20:52:12,417 - INFO - allennlp.common.params - iterator.track_epoch = False\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.common.params - validation_iterator = None\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.common.params - trainer.no_grad = ()\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - Following parameters are Frozen  (without gradient):\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - embedding.token_embedder_tokens.weight\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - Following parameters are Tunable (with gradient):\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - encoder._module.weight_ih_l0\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - encoder._module.weight_hh_l0\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - encoder._module.bias_ih_l0\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - encoder._module.bias_hh_l0\r\n","2019-04-06 20:52:12,418 - INFO - allennlp.training.trainer - classifier._linear_layers.0.weight\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.training.trainer - classifier._linear_layers.0.bias\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.patience = None\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.validation_metric = -loss\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.shuffle = True\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.num_epochs = 4\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.cuda_device = 0\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.grad_norm = None\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.grad_clipping = 5\r\n","2019-04-06 20:52:12,419 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\r\n","2019-04-06 20:52:16,328 - INFO - allennlp.common.params - trainer.optimizer.type = adam\r\n","2019-04-06 20:52:16,329 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\r\n","2019-04-06 20:52:16,329 - INFO - allennlp.training.optimizers - Number of trainable parameters: 93761\r\n","2019-04-06 20:52:16,329 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\r\n","2019-04-06 20:52:16,329 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 20:52:16,329 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 20:52:16,329 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = reduce_on_plateau\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 0.5\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.patience = 5\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 1\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.model_save_interval = None\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.summary_interval = 10\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.histogram_interval = 100\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.should_log_learning_rate = True\r\n","2019-04-06 20:52:16,330 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\r\n","2019-04-06 20:52:16,331 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\r\n","2019-04-06 20:52:16,438 - INFO - allennlp.training.trainer - Beginning training.\r\n","2019-04-06 20:52:16,438 - INFO - allennlp.training.trainer - Epoch 0/3\r\n","2019-04-06 20:52:16,438 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 4200.192\r\n","2019-04-06 20:52:16,528 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 761\r\n","2019-04-06 20:52:16,529 - INFO - allennlp.training.trainer - Training\r\n","loss: 0.1507 ||: : 2821it [15:33,  2.05it/s]\r\n","2019-04-06 21:07:49,837 - INFO - allennlp.training.trainer - Validating\r\n","accuracy: 0.9572, loss: 0.1284 ||: : 576it [02:39,  3.63it/s]"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nTlwlPthhcKn"},"source":["## Evaluate the model's performance on the train and val sets"]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"9JPiLXMwhcKo","outputId":"11cdcde5-5c5d-4682-a94d-2938b40f34bf"},"source":["!allennlp evaluate --cuda-device 0 --include-package jigsaw ./logs/model.tar.gz train.csv\n","!allennlp evaluate --cuda-device 0 --include-package jigsaw ./logs/model.tar.gz val.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 22:07:42,342 - INFO - allennlp.models.archival - loading archive file ./logs/model.tar.gz\r\n","2019-04-06 22:07:42,343 - INFO - allennlp.models.archival - extracting archive file ./logs/model.tar.gz to temp dir /tmp/tmpfk7rmpiw\r\n","2019-04-06 22:07:43,386 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpfk7rmpiw/vocabulary.\r\n","2019-04-06 22:07:43,484 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 22:07:43,485 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 22:07:43,485 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 22:07:43,485 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 22:07:43,736 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 22:07:46,175 - INFO - allennlp.common.checks - Pytorch version: 1.0.1.post2\r\n","2019-04-06 22:07:46,175 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 22:07:46,176 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 22:07:46,176 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 22:07:46,176 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 22:07:46,176 - INFO - allennlp.commands.evaluate - Reading evaluation data from train.csv\r\n","2019-04-06 22:07:46,176 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']], 'type': 'bucket'} and extras set()\r\n","2019-04-06 22:07:46,177 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']]} and extras set()\r\n","2019-04-06 22:07:46,177 - INFO - allennlp.training.util - Iterating over dataset\r\n","accuracy: 0.96, loss: 0.10 ||: : 2821it [13:16,  2.28it/s]\r\n","2019-04-06 22:21:02,716 - INFO - allennlp.commands.evaluate - Finished evaluating.\r\n","2019-04-06 22:21:02,716 - INFO - allennlp.commands.evaluate - Metrics:\r\n","2019-04-06 22:21:02,716 - INFO - allennlp.commands.evaluate - accuracy: 0.9637931738992824\r\n","2019-04-06 22:21:02,716 - INFO - allennlp.commands.evaluate - loss: 0.10184237466598817\r\n","2019-04-06 22:21:02,720 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpfk7rmpiw\r\n","Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 22:21:07,134 - INFO - allennlp.models.archival - loading archive file ./logs/model.tar.gz\r\n","2019-04-06 22:21:07,135 - INFO - allennlp.models.archival - extracting archive file ./logs/model.tar.gz to temp dir /tmp/tmpn61xdqiz\r\n","2019-04-06 22:21:08,217 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpn61xdqiz/vocabulary.\r\n","2019-04-06 22:21:08,312 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 22:21:08,313 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 22:21:08,313 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 22:21:08,314 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 22:21:08,567 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 22:21:11,039 - INFO - allennlp.common.checks - Pytorch version: 1.0.1.post2\r\n","2019-04-06 22:21:11,039 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 22:21:11,040 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 22:21:11,040 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 22:21:11,040 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 22:21:11,040 - INFO - allennlp.commands.evaluate - Reading evaluation data from val.csv\r\n","2019-04-06 22:21:11,040 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']], 'type': 'bucket'} and extras set()\r\n","2019-04-06 22:21:11,041 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 512, 'sorting_keys': [['comment_text', 'num_tokens']]} and extras set()\r\n","2019-04-06 22:21:11,041 - INFO - allennlp.training.util - Iterating over dataset\r\n","accuracy: 0.96, loss: 0.11 ||: : 706it [03:11,  4.20it/s]\r\n","2019-04-06 22:24:22,317 - INFO - allennlp.commands.evaluate - Finished evaluating.\r\n","2019-04-06 22:24:22,317 - INFO - allennlp.commands.evaluate - Metrics:\r\n","2019-04-06 22:24:22,317 - INFO - allennlp.commands.evaluate - accuracy: 0.9607618256111919\r\n","2019-04-06 22:24:22,317 - INFO - allennlp.commands.evaluate - loss: 0.11243568266881762\r\n","2019-04-06 22:24:22,321 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpn61xdqiz\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"Wlwp_scVhcKr","outputId":"62178d01-14ee-4f4b-d00e-b760cf44b589"},"source":["%%time\n","!allennlp predict --output-file ./train_preds.csv --batch-size 64 --cuda-device 0 --use-dataset-reader --predictor jigsaw --include-package jigsaw --silent ./logs/model.tar.gz train.csv\n","# From https://superuser.com/questions/246837/how-do-i-add-text-to-the-beginning-of-a-file-in-bash\n","!sed -i '1s/^/prediction\\n/' train_preds.csv\n","train_preds = pd.read_csv('train_preds.csv')\n","train_roc_auc_score = roc_auc_score(train_df.target.values > 0.5, train_preds.prediction.values)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 22:24:28,401 - INFO - allennlp.models.archival - loading archive file ./logs/model.tar.gz\r\n","2019-04-06 22:24:28,402 - INFO - allennlp.models.archival - extracting archive file ./logs/model.tar.gz to temp dir /tmp/tmp720urff3\r\n","2019-04-06 22:24:29,448 - INFO - allennlp.common.params - vocabulary.type = default\r\n","2019-04-06 22:24:29,448 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmp720urff3/vocabulary.\r\n","2019-04-06 22:24:29,545 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 22:24:29,546 - INFO - allennlp.common.params - model.type = baseline\r\n","2019-04-06 22:24:29,546 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 22:24:29,546 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.type = basic\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.embedder_to_indexer_map = None\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.allow_unmatched_keys = False\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.token_embedders = None\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.type = embedding\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.num_embeddings = None\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.vocab_namespace = tokens\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.embedding_dim = 300\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.pretrained_file = None\r\n","2019-04-06 22:24:29,547 - INFO - allennlp.common.params - model.embeddings.tokens.projection_dim = None\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.trainable = False\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.padding_index = None\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.max_norm = None\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.norm_type = 2.0\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.scale_grad_by_freq = False\r\n","2019-04-06 22:24:29,548 - INFO - allennlp.common.params - model.embeddings.tokens.sparse = False\r\n","2019-04-06 22:24:29,801 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.type = lstm\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.bidirectional = False\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.hidden_size = 64\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.input_size = 300\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.num_layers = 1\r\n","2019-04-06 22:24:29,802 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:24:29,804 - INFO - allennlp.common.params - model.classifier.input_dim = 64\r\n","2019-04-06 22:24:29,804 - INFO - allennlp.common.params - model.classifier.num_layers = 1\r\n","2019-04-06 22:24:29,804 - INFO - allennlp.common.params - model.classifier.hidden_dims = 1\r\n","2019-04-06 22:24:29,804 - INFO - allennlp.common.params - model.classifier.activations = linear\r\n","2019-04-06 22:24:29,804 - INFO - allennlp.common.params - model.classifier.dropout = 0.0\r\n","2019-04-06 22:24:32,387 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 22:24:32,387 - INFO - allennlp.common.params - dataset_reader.type = jigsaw\r\n","2019-04-06 22:24:32,387 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 22:24:32,387 - INFO - allennlp.common.params - dataset_reader.root_path = ./\r\n","2019-04-06 22:24:32,388 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 22:24:32,388 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = simple\r\n","2019-04-06 22:24:32,388 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 22:24:32,388 - INFO - allennlp.common.params - dataset_reader.lazy = True\r\n","2019-04-06 22:24:32,388 - INFO - allennlp.common.params - dataset_reader.subset = False\r\n","2019-04-06 22:24:46,263 - WARNING - allennlp.models.model - Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\r\n","2019-04-06 22:40:05,153 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmp720urff3\r\n","CPU times: user 14.8 s, sys: 3.4 s, total: 18.2 s\n","Wall time: 15min 44s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"5XH_Amu2hcKv","outputId":"cfed9918-c279-4ea2-f97c-954c5bafdbd2"},"source":["%%time\n","!allennlp predict --output-file ./val_preds.csv --batch-size 64 --cuda-device 0 --use-dataset-reader --predictor jigsaw --include-package jigsaw --silent ./logs/model.tar.gz val.csv\n","# From https://superuser.com/questions/246837/how-do-i-add-text-to-the-beginning-of-a-file-in-bash\n","!sed -i '1s/^/prediction\\n/' val_preds.csv\n","val_preds = pd.read_csv('val_preds.csv')\n","val_roc_auc_score = roc_auc_score(val_df.target.values > 0.5, val_preds.prediction.values)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 22:40:13,555 - INFO - allennlp.models.archival - loading archive file ./logs/model.tar.gz\r\n","2019-04-06 22:40:13,556 - INFO - allennlp.models.archival - extracting archive file ./logs/model.tar.gz to temp dir /tmp/tmpiw2mry9z\r\n","2019-04-06 22:40:14,773 - INFO - allennlp.common.params - vocabulary.type = default\r\n","2019-04-06 22:40:14,774 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpiw2mry9z/vocabulary.\r\n","2019-04-06 22:40:14,888 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 22:40:14,889 - INFO - allennlp.common.params - model.type = baseline\r\n","2019-04-06 22:40:14,889 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.type = basic\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.embedder_to_indexer_map = None\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.allow_unmatched_keys = False\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.token_embedders = None\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.tokens.type = embedding\r\n","2019-04-06 22:40:14,890 - INFO - allennlp.common.params - model.embeddings.tokens.num_embeddings = None\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.vocab_namespace = tokens\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.embedding_dim = 300\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.pretrained_file = None\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.projection_dim = None\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.trainable = False\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.padding_index = None\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.max_norm = None\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.norm_type = 2.0\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.scale_grad_by_freq = False\r\n","2019-04-06 22:40:14,891 - INFO - allennlp.common.params - model.embeddings.tokens.sparse = False\r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.params - model.encoder.type = lstm\r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 22:40:15,193 - INFO - allennlp.common.params - model.encoder.bidirectional = False\r\n","2019-04-06 22:40:15,194 - INFO - allennlp.common.params - model.encoder.hidden_size = 64\r\n","2019-04-06 22:40:15,194 - INFO - allennlp.common.params - model.encoder.input_size = 300\r\n","2019-04-06 22:40:15,194 - INFO - allennlp.common.params - model.encoder.num_layers = 1\r\n","2019-04-06 22:40:15,194 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:40:15,195 - INFO - allennlp.common.params - model.classifier.input_dim = 64\r\n","2019-04-06 22:40:15,195 - INFO - allennlp.common.params - model.classifier.num_layers = 1\r\n","2019-04-06 22:40:15,196 - INFO - allennlp.common.params - model.classifier.hidden_dims = 1\r\n","2019-04-06 22:40:15,196 - INFO - allennlp.common.params - model.classifier.activations = linear\r\n","2019-04-06 22:40:15,196 - INFO - allennlp.common.params - model.classifier.dropout = 0.0\r\n","2019-04-06 22:40:18,001 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 22:40:18,001 - INFO - allennlp.common.params - dataset_reader.type = jigsaw\r\n","2019-04-06 22:40:18,001 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 22:40:18,002 - INFO - allennlp.common.params - dataset_reader.root_path = ./\r\n","2019-04-06 22:40:18,002 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 22:40:18,002 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = simple\r\n","2019-04-06 22:40:18,002 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 22:40:18,002 - INFO - allennlp.common.params - dataset_reader.lazy = True\r\n","2019-04-06 22:40:18,003 - INFO - allennlp.common.params - dataset_reader.subset = False\r\n","2019-04-06 22:40:21,654 - WARNING - allennlp.models.model - Encountered the loss key in the model's return dictionary which couldn't be split by the batch size. Key will be ignored.\r\n","2019-04-06 22:44:03,528 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpiw2mry9z\r\n","CPU times: user 3.68 s, sys: 996 ms, total: 4.68 s\n","Wall time: 3min 56s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sMeyzcM0hcK2","outputId":"9b1b7fc4-9281-4063-c5bf-20f14d91540a"},"source":["!cat logs/metrics.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{\r\n","  \"best_epoch\": 3,\r\n","  \"peak_cpu_memory_MB\": 6563.652,\r\n","  \"peak_gpu_0_memory_MB\": 1329,\r\n","  \"training_duration\": \"01:15:04\",\r\n","  \"training_start_epoch\": 0,\r\n","  \"training_epochs\": 3,\r\n","  \"epoch\": 3,\r\n","  \"training_loss\": 0.1069820237150221,\r\n","  \"training_cpu_memory_MB\": 6563.652,\r\n","  \"training_gpu_0_memory_MB\": 1329,\r\n","  \"validation_accuracy\": 0.9607618256111919,\r\n","  \"validation_loss\": 0.11243568266354101,\r\n","  \"best_validation_accuracy\": 0.9607618256111919,\r\n","  \"best_validation_loss\": 0.11243568266354101\r\n","}"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D_vkoUXwhcK8","outputId":"43cd2cdf-f6dc-401e-b7fd-2462b4fa69f5"},"source":["print(f'Train ROC-AUC: {round(train_roc_auc_score, 4)}')\n","print(f'Val ROC-AUC: {round(val_roc_auc_score, 4)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train ROC-AUC: 0.9543\n","Val ROC-AUC: 0.9415\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3VEmfDD9hcLB"},"source":["## Predict on the test set and save submission"]},{"cell_type":"code","metadata":{"_kg_hide-output":true,"id":"wbHi37xjhcLC","outputId":"8dc6cb55-afc4-4925-c359-2119a3e8df43"},"source":["%%time\n","!allennlp predict --output-file ./test_preds.csv --batch-size 64 --cuda-device 0 --use-dataset-reader --predictor jigsaw --include-package jigsaw --silent ./logs/model.tar.gz ../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv\n","# From https://superuser.com/questions/246837/how-do-i-add-text-to-the-beginning-of-a-file-in-bash\n","!sed -i '1s/^/prediction\\n/' test_preds.csv\n","test_preds = pd.read_csv('test_preds.csv')\n","sample_submission['prediction'] = test_preds['prediction'].values\n","mlc.kaggle.save_sub(sample_submission, 'submission.csv')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\r\n","2019-04-06 22:44:10,079 - INFO - allennlp.models.archival - loading archive file ./logs/model.tar.gz\r\n","2019-04-06 22:44:10,080 - INFO - allennlp.models.archival - extracting archive file ./logs/model.tar.gz to temp dir /tmp/tmpj_zryeci\r\n","2019-04-06 22:44:11,118 - INFO - allennlp.common.params - vocabulary.type = default\r\n","2019-04-06 22:44:11,118 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpj_zryeci/vocabulary.\r\n","2019-04-06 22:44:11,214 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}, 'type': 'baseline'} and extras {'vocab'}\r\n","2019-04-06 22:44:11,214 - INFO - allennlp.common.params - model.type = baseline\r\n","2019-04-06 22:44:11,214 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.model.Baseline'> from params {'classifier': {'activations': 'linear', 'hidden_dims': 1, 'input_dim': 64, 'num_layers': 1}, 'embeddings': {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}}, 'encoder': {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab'}\r\n","2019-04-06 22:44:11,214 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'tokens': {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'}} and extras {'vocab'}\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.type = basic\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.embedder_to_indexer_map = None\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.allow_unmatched_keys = False\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.token_embedders = None\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding_dim': 300, 'trainable': False, 'type': 'embedding'} and extras {'vocab'}\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.tokens.type = embedding\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.tokens.num_embeddings = None\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.tokens.vocab_namespace = tokens\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.tokens.embedding_dim = 300\r\n","2019-04-06 22:44:11,215 - INFO - allennlp.common.params - model.embeddings.tokens.pretrained_file = None\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.projection_dim = None\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.trainable = False\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.padding_index = None\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.max_norm = None\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.norm_type = 2.0\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.scale_grad_by_freq = False\r\n","2019-04-06 22:44:11,216 - INFO - allennlp.common.params - model.embeddings.tokens.sparse = False\r\n","2019-04-06 22:44:11,470 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'bidirectional': False, 'hidden_size': 64, 'input_size': 300, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab'}\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.type = lstm\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.bidirectional = False\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.hidden_size = 64\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.input_size = 300\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.num_layers = 1\r\n","2019-04-06 22:44:11,471 - INFO - allennlp.common.params - model.encoder.batch_first = True\r\n","2019-04-06 22:44:11,473 - INFO - allennlp.common.params - model.classifier.input_dim = 64\r\n","2019-04-06 22:44:11,473 - INFO - allennlp.common.params - model.classifier.num_layers = 1\r\n","2019-04-06 22:44:11,473 - INFO - allennlp.common.params - model.classifier.hidden_dims = 1\r\n","2019-04-06 22:44:11,473 - INFO - allennlp.common.params - model.classifier.activations = linear\r\n","2019-04-06 22:44:11,473 - INFO - allennlp.common.params - model.classifier.dropout = 0.0\r\n","2019-04-06 22:44:14,236 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}, 'type': 'jigsaw'} and extras set()\r\n","2019-04-06 22:44:14,236 - INFO - allennlp.common.params - dataset_reader.type = jigsaw\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.JigsawDatasetReader'> from params {'lazy': True, 'root_path': './', 'subset': False, 'tokenizer': {'type': 'simple'}} and extras set()\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.params - dataset_reader.root_path = ./\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'type': 'simple'} and extras set()\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = simple\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.from_params - instantiating class <class 'jigsaw.dataset.LatexTokenizer'> from params {} and extras set()\r\n","2019-04-06 22:44:14,237 - INFO - allennlp.common.params - dataset_reader.lazy = True\r\n","2019-04-06 22:44:14,238 - INFO - allennlp.common.params - dataset_reader.subset = False\r\n","2019-04-06 22:45:10,485 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpj_zryeci\r\n","CPU times: user 1.32 s, sys: 364 ms, total: 1.68 s\n","Wall time: 1min 5s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xqjuAK5BhcLF","outputId":"cabbfc26-f27a-486f-a8d4-ed4fd502623c"},"source":["sample_submission.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>prediction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7000000</td>\n","      <td>0.007651</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7000001</td>\n","      <td>0.000628</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7000002</td>\n","      <td>0.001997</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7000003</td>\n","      <td>0.000672</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7000004</td>\n","      <td>0.961583</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id  prediction\n","0  7000000    0.007651\n","1  7000001    0.000628\n","2  7000002    0.001997\n","3  7000003    0.000672\n","4  7000004    0.961583"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"LPNCzey0hcLJ"},"source":["## Delete unnecessary files to free up more space"]},{"cell_type":"code","metadata":{"id":"XJuXMnvthcLK","outputId":"a6a8c5ff-1881-48bb-83a3-c5debbf7f79a"},"source":["!rm -rf logs\n","!rm out.txt\n","!rm config.json"],"execution_count":null,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'out.txt': No such file or directory\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GzFITDBmhcLO"},"source":["!rm -rf packages"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylXzj48BhcLR"},"source":["\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}