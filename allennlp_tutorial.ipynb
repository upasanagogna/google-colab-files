{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"allennlp_tutorial.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"68ZZ3Q2pnNhc"},"source":["## **AllenNLP demo**\n","\n","This is a demo for prediction venue based on title and abstract of the paper\n","\n","reference: https://github.com/allenai/allennlp-as-a-library-example"]},{"cell_type":"code","metadata":{"id":"-y5_HI6_uSFV","executionInfo":{"status":"ok","timestamp":1604920638713,"user_tz":-330,"elapsed":4604,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"866cb957-40d0-4341-bab1-8dd5f732c7a5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install allennlp-models==1.0.0\n","\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Collecting allennlp-models==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d5/9ee1d0b8c217b6978e42e54fbab8bafe9e792f0f8262f381dde44cee44ae/allennlp_models-1.0.0-py3-none-any.whl (282kB)\n","\u001b[K     |████████████████████████████████| 286kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (1.1)\n","Requirement already satisfied: allennlp==1.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (1.0.0)\n","Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (1.1)\n","Collecting conllu==3.0\n","  Downloading https://files.pythonhosted.org/packages/66/0b/a8863b5c14aee200a13a0f8c28550fd0132e947ae88441c9f517eb84613b/conllu-3.0-py2.py3-none-any.whl\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp-models==1.0.0) (3.2.5)\n","Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.16.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.10.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (0.22.2.post1)\n","Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.0.12)\n","Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.4.1)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.23.0)\n","Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.4.1)\n","Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.2.4)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (3.6.4)\n","Requirement already satisfied: transformers<2.12,>=2.9 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (2.11.0)\n","Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (0.16.0)\n","Requirement already satisfied: torch<1.6.0,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.5.1)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0->allennlp-models==1.0.0) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp-models==1.0.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0->allennlp-models==1.0.0) (3.12.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (0.10.0)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0->allennlp-models==1.0.0) (1.19.13)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0->allennlp-models==1.0.0) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0->allennlp-models==1.0.0) (3.0.4)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0->allennlp-models==1.0.0) (2.0.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (2.0.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (3.0.2)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.8.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (1.1.3)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (50.3.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0->allennlp-models==1.0.0) (7.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (1.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (20.2.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0->allennlp-models==1.0.0) (8.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (20.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.1.94)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.0.43)\n","Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (0.7.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0->allennlp-models==1.0.0) (0.16.0)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->allennlp==1.0.0->allennlp-models==1.0.0) (2.8.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0->allennlp-models==1.0.0) (3.4.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0->allennlp-models==1.0.0) (7.1.2)\n","Installing collected packages: conllu, allennlp-models\n","  Found existing installation: conllu 4.2.1\n","    Uninstalling conllu-4.2.1:\n","      Successfully uninstalled conllu-4.2.1\n","  Found existing installation: allennlp-models 1.2.0\n","    Uninstalling allennlp-models-1.2.0:\n","      Successfully uninstalled allennlp-models-1.2.0\n","Successfully installed allennlp-models-1.0.0 conllu-3.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["allennlp_models","conllu"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"xdGredKQnWfK","executionInfo":{"status":"ok","timestamp":1604919351391,"user_tz":-330,"elapsed":115873,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"f32aca2f-62b0-4635-93df-028c53b70a2f","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install allennlp==1.0.0 \n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Collecting allennlp==1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/49/bf0ec241496a82c9dd2f0b6ff6f8156b6b2b72b849df8c00a4f2bcf61485/allennlp-1.0.0-py3-none-any.whl (473kB)\n","\u001b[K     |████████████████████████████████| 481kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.7)\n","Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.16.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.2.5)\n","Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (4.41.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.10.0)\n","Collecting overrides==3.0.0\n","  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.23.0)\n","Collecting torch<1.6.0,>=1.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n","\u001b[K     |████████████████████████████████| 753.2MB 22kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.16.13)\n","Requirement already satisfied: spacy<2.3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.2.4)\n","Collecting transformers<2.12,>=2.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 40.0MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (3.6.4)\n","Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (0.22.2.post1)\n","Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.0.0) (2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp==1.0.0) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.0.0) (2.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.6.0,>=1.5.0->allennlp==1.0.0) (0.16.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.3.3)\n","Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (1.19.13)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp==1.0.0) (0.10.0)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (7.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.3)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.1.3)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (3.0.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (0.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (50.3.2)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (1.0.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.3,>=2.1.0->allennlp==1.0.0) (2.0.4)\n","Collecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 44.9MB/s \n","\u001b[?25hRequirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (0.0.43)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (0.1.94)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<2.12,>=2.9->allennlp==1.0.0) (20.4)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.9.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (8.6.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (1.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (0.7.1)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.0.0) (20.2.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.0.0) (2.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.0.0) (0.17.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.0.0) (3.12.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->allennlp==1.0.0) (2.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<2.12,>=2.9->allennlp==1.0.0) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<2.12,>=2.9->allennlp==1.0.0) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp==1.0.0) (3.4.0)\n","Building wheels for collected packages: overrides\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=a689d7a5022a7d002f041aaa87d8fa7fa7d6cfa1db58b60cc3a20372c74f23b5\n","  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n","Successfully built overrides\n","\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: allennlp-models 1.2.0 has requirement allennlp==1.2.0, but you'll have allennlp 1.0.0 which is incompatible.\u001b[0m\n","Installing collected packages: overrides, torch, tokenizers, transformers, allennlp\n","  Found existing installation: overrides 3.1.0\n","    Uninstalling overrides-3.1.0:\n","      Successfully uninstalled overrides-3.1.0\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: tokenizers 0.9.2\n","    Uninstalling tokenizers-0.9.2:\n","      Successfully uninstalled tokenizers-0.9.2\n","  Found existing installation: transformers 3.4.0\n","    Uninstalling transformers-3.4.0:\n","      Successfully uninstalled transformers-3.4.0\n","  Found existing installation: allennlp 1.2.0\n","    Uninstalling allennlp-1.2.0:\n","      Successfully uninstalled allennlp-1.2.0\n","Successfully installed allennlp-1.0.0 overrides-3.0.0 tokenizers-0.7.0 torch-1.5.1 transformers-2.11.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["allennlp","overrides","tokenizers","torch","transformers"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/bin/bash: allennlp-models==1.0.0: command not found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xQotjyInn2YO","executionInfo":{"status":"ok","timestamp":1604919352480,"user_tz":-330,"elapsed":112635,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"b62783f3-4ba6-4421-bed4-91c8e23066dd","colab":{"base_uri":"https://localhost:8080/"}},"source":["from allennlp.predictors.predictor import Predictor\n","import allennlp_models.classification\n","predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz\")\n","predictor.predict(\n","  sentence=\"a very well-made, funny and entertaining picture.\"\n",")"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': '1',\n"," 'logits': [2.7240731716156006, -2.6614115238189697],\n"," 'probs': [0.995438277721405, 0.004561713896691799],\n"," 'token_ids': [4, 72, 91, 186, 112, 2, 55, 5, 128, 199, 7],\n"," 'tokens': ['a',\n","  'very',\n","  'well',\n","  '-',\n","  'made',\n","  ',',\n","  'funny',\n","  'and',\n","  'entertaining',\n","  'picture',\n","  '.']}"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"5TVxBjcmoNfg","executionInfo":{"status":"ok","timestamp":1604919352483,"user_tz":-330,"elapsed":108950,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}}},"source":[""],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"kwkoab-WnNhd","executionInfo":{"status":"ok","timestamp":1604920666321,"user_tz":-330,"elapsed":1044,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}}},"source":["import json\n","from typing import Iterator, List, Dict, Optional\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# for dataset reader\n","from allennlp.data import Instance\n","from allennlp.data.fields import TextField, SequenceLabelField, LabelField\n","from allennlp.data.dataset_readers import DatasetReader\n","from allennlp.common.file_utils import cached_path\n","from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n","from allennlp.data.tokenizers import Token, Tokenizer\n","from allennlp.data.vocabulary import Vocabulary\n","\n","# read pretrained embedding from AWS S3\n","from allennlp.modules.token_embedders.embedding import _read_embeddings_from_text_file\n","\n","# for building model\n","from allennlp.models import Model\n","from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n","from allennlp.modules.token_embedders import Embedding\n","from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n","from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n","from allennlp.modules import FeedForward\n","from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n","from allennlp.nn import InitializerApplicator, RegularizerApplicator\n","from allennlp.training.metrics import CategoricalAccuracy\n","#from allennlp.data.iterators import BucketIterator\n","from allennlp.training.trainer import Trainer"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bc_iaKxlnNhk"},"source":["## **Create classes for the model**\n","\n","Generally, we need to implement 2 classes for AllenNLP including\n","\n","- `DatasetReader`: to read dataset and return `Instance` class\n","- `Model`: input `Instance` class and return output prediction\n","\n","`Model` consists of the Sequence to Vector model (`Seq2Vec`)\n","\n","<img src=\"figures/bilstm.png\" width=\"300\"/>\n","\n","\n","and we use the combination of vectors to predict venue\n","\n","<img src=\"figures/venue_prediction.png\" width=\"300\"/>"]},{"cell_type":"code","metadata":{"id":"xU8NcZUTnNhl","executionInfo":{"status":"ok","timestamp":1604920858245,"user_tz":-330,"elapsed":3282,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}}},"source":["class PublicationDatasetReader(DatasetReader):\n","    \"\"\"\n","    DatasetReader for publication and venue dataaet\n","    \"\"\"\n","    def __init__(self, \n","                 tokenizer: Tokenizer = None,\n","                 token_indexers: Dict[str, TokenIndexer] = None, \n","                 lazy: bool = False) -> None:\n","        super().__init__(lazy)\n","        self._tokenizer = tokenizer or WordTokenizer()\n","        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n","\n","    def _read(self, file_path: str) -> Iterator[Instance]:\n","        \"\"\"\n","        Read publication and venue dataset in JSON format\n","        \n","        Data is in the following format:\n","            {\"title\": ..., \"paperAbstract\": ..., \"venue\": ...}\n","        \"\"\"\n","        with open(cached_path(file_path), \"r\") as data_file:\n","            for line in data_file:\n","                line = line.strip(\"\\n\")\n","                if not line:\n","                    continue\n","                paper_json = json.loads(line)\n","                title = paper_json['title']\n","                abstract = paper_json['paperAbstract']\n","                venue = paper_json['venue']\n","                yield self.text_to_instance(title, abstract, venue)\n","        \n","    def text_to_instance(self, \n","                         title: str, \n","                         abstract: str, \n","                         venue: str=None) -> Instance:\n","        \"\"\"\n","        Turn title, abstract, and venue to instance\n","        \"\"\"\n","        tokenized_title = self._tokenizer.tokenize(title)\n","        tokenized_abstract = self._tokenizer.tokenize(abstract)\n","        title_field = TextField(tokenized_title, self._token_indexers)\n","        abstract_field = TextField(tokenized_abstract, self._token_indexers)\n","        fields = {'title': title_field, \n","                  'abstract': abstract_field}\n","        if venue is not None:\n","            fields['label'] = LabelField(venue)\n","        return Instance(fields)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERiELA0AnNhq","executionInfo":{"status":"ok","timestamp":1604920859857,"user_tz":-330,"elapsed":4273,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}}},"source":["class AcademicPaperClassifier(Model):\n","    \"\"\"\n","    Model to classify venue based on input title and abstract\n","    \"\"\"\n","    def __init__(self, \n","                 vocab: Vocabulary,\n","                 text_field_embedder: TextFieldEmbedder,\n","                 title_encoder: Seq2VecEncoder,\n","                 abstract_encoder: Seq2VecEncoder,\n","                 classifier_feedforward: FeedForward,\n","                 initializer: InitializerApplicator = InitializerApplicator(),\n","                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n","        super(AcademicPaperClassifier, self).__init__(vocab, regularizer)\n","        self.text_field_embedder = text_field_embedder\n","        self.num_classes = self.vocab.get_vocab_size(\"labels\")\n","        self.title_encoder = title_encoder\n","        self.abstract_encoder = abstract_encoder\n","        self.classifier_feedforward = classifier_feedforward\n","        self.metrics = {\n","                \"accuracy\": CategoricalAccuracy(),\n","                \"accuracy3\": CategoricalAccuracy(top_k=3)\n","        }\n","        self.loss = torch.nn.CrossEntropyLoss()\n","        initializer(self)\n","    \n","    def forward(self, \n","                title: Dict[str, torch.LongTensor],\n","                abstract: Dict[str, torch.LongTensor],\n","                label: torch.LongTensor = None) -> Dict[str, torch.Tensor]:\n","        \n","        embedded_title = self.text_field_embedder(title)\n","        title_mask = get_text_field_mask(title)\n","        encoded_title = self.title_encoder(embedded_title, title_mask)\n","\n","        embedded_abstract = self.text_field_embedder(abstract)\n","        abstract_mask = get_text_field_mask(abstract)\n","        encoded_abstract = self.abstract_encoder(embedded_abstract, abstract_mask)\n","\n","        logits = self.classifier_feedforward(torch.cat([encoded_title, encoded_abstract], dim=-1))\n","        class_probabilities = F.softmax(logits, dim=-1)\n","        argmax_indices = np.argmax(class_probabilities.cpu().data.numpy(), axis=-1)\n","        labels = [self.vocab.get_token_from_index(x, namespace=\"labels\") for x in argmax_indices]\n","        output_dict = {\n","            'logits': logits, \n","            'class_probabilities': class_probabilities,\n","            'predicted_label': labels\n","        }\n","        if label is not None:\n","            loss = self.loss(logits, label)\n","            for metric in self.metrics.values():\n","                metric(logits, label)\n","            output_dict[\"loss\"] = loss\n","\n","        return output_dict"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DB-JHtZxnNht"},"source":["## **Read dataset**\n","\n","- `cached_path`: can cache the file locally\n","- `BasicTextFieldEmbedder` takes a mapping from index names to embeddings"]},{"cell_type":"code","metadata":{"id":"8-IrL_LnnNhu","executionInfo":{"status":"ok","timestamp":1604920859858,"user_tz":-330,"elapsed":2506,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}}},"source":["train_data_path = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/train.jsonl\"\n","validation_data_path = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/academic-papers-example/dev.jsonl\"\n","pretrained_file = \"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.100d.txt.gz\""],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsTkg2uUnNhy","executionInfo":{"status":"error","timestamp":1604920862410,"user_tz":-330,"elapsed":4093,"user":{"displayName":"Upasana Gogna","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhF152qiue1VxC4QwqNWg_qUQ2Dsf6UQhenBLsa6g=s64","userId":"17402908673397364006"}},"outputId":"b6162e22-5e21-4820-fb38-70b3f649cc55","colab":{"base_uri":"https://localhost:8080/","height":287}},"source":["reader = PublicationDatasetReader()"],"execution_count":30,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-f14376514aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPublicationDatasetReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-04fd8e9d1da7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, token_indexers, lazy)\u001b[0m\n\u001b[1;32m      8\u001b[0m                  lazy: bool = False) -> None:\n\u001b[1;32m      9\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mWordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_indexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_indexers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSingleIdTokenIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'WordTokenizer' is not defined"]}]},{"cell_type":"code","metadata":{"id":"kGABxUrYnNh1"},"source":["instance = reader.text_to_instance(\"This is a great paper.\", \n","                                   \"Indeed, this is a great paper of all time\", \n","                                   \"Nature\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"jJQmQ9G6nNh4","outputId":"5db98400-2d19-4350-c9d4-582a77661d5a"},"source":["train_dataset = reader.read(cached_path(train_data_path))\n","validation_dataset = reader.read(cached_path(validation_data_path))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["15000it [01:12, 206.74it/s]\n","2000it [00:10, 199.56it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"w5Qm5V0unNh_","outputId":"9a764635-bd85-4beb-b5d9-ca56ee7e5c1a"},"source":["# building vocabulary\n","vocab = Vocabulary.from_instances(train_dataset + validation_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 17000/17000 [00:05<00:00, 3205.53it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xT8JuQHonNiC","outputId":"da4ea43f-c3a6-46d7-bfe6-fccddbb89f08"},"source":["# load pre-trained embedding\n","embedding_matrix = _read_embeddings_from_text_file(file_uri=pretrained_file, \n","                                                   embedding_dim=100, \n","                                                   vocab=vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["400000it [00:03, 100679.01it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PoBbQnO9nNiI","outputId":"c53ef40f-b5a4-4c06-923f-590cb337c59d"},"source":["print(embedding_matrix.size()) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([64714, 100])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KOQOGgfOnNiL"},"source":["EMBEDDING_DIM = 100\n","HIDDEN_DIM = 100\n","num_classes = len(vocab.get_index_to_token_vocabulary('labels'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4xhzeF8xnNiO"},"source":["# embedding\n","token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'), \n","                            embedding_dim=EMBEDDING_DIM,\n","                            weight=embedding_matrix)\n","word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZ8CSOcFnNiS"},"source":["lstm_title = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, \n","                                                 batch_first=True, bidirectional=True))\n","lstm_abstract = PytorchSeq2VecWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, \n","                                                    batch_first=True, bidirectional=True))\n","feed_forward = torch.nn.Linear(2 * 2 * HIDDEN_DIM, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MxH_xndKnNiW"},"source":["model = AcademicPaperClassifier(vocab,\n","                                word_embeddings, \n","                                lstm_title, \n","                                lstm_abstract, \n","                                feed_forward)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R8wBlWY7nNia"},"source":["optimizer = optim.SGD(model.parameters(), lr=0.005)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8YRuiYCnNie"},"source":["iterator = BucketIterator(batch_size=64, \n","                          sorting_keys=[(\"abstract\", \"num_tokens\"), \n","                                        (\"title\", \"num_tokens\")])\n","iterator.index_with(vocab) # index with the created vocabulary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMZCd0vknNig"},"source":["trainer = Trainer(\n","    model=model,\n","    optimizer=optimizer,\n","    iterator=iterator,\n","    train_dataset=train_dataset,\n","    validation_dataset=validation_dataset,\n","    patience=2,\n","    num_epochs=5,\n","    serialization_dir='output'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"VOj8h6hBnNik","outputId":"9cadd904-25a9-40a5-f044-d61ee960d84e"},"source":["trainer.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loss: 0.7956 ||: 100%|██████████| 235/235 [06:06<00:00,  1.56s/it]\n","loss: 0.6613 ||: 100%|██████████| 32/32 [00:05<00:00,  5.60it/s]\n","loss: 0.5951 ||: 100%|██████████| 235/235 [06:54<00:00,  1.77s/it]\n","loss: 0.6056 ||: 100%|██████████| 32/32 [00:10<00:00,  3.14it/s]\n","loss: 0.5466 ||: 100%|██████████| 235/235 [07:42<00:00,  1.97s/it]\n","loss: 0.5737 ||: 100%|██████████| 32/32 [00:07<00:00,  4.56it/s]\n","loss: 0.5181 ||: 100%|██████████| 235/235 [07:27<00:00,  1.91s/it]\n","loss: 0.5616 ||: 100%|██████████| 32/32 [00:07<00:00,  4.00it/s]\n","loss: 0.5016 ||: 100%|██████████| 235/235 [07:58<00:00,  2.04s/it]\n","loss: 0.5476 ||: 100%|██████████| 32/32 [00:08<00:00,  3.94it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'training_duration': '00:36:48',\n"," 'training_start_epoch': 0,\n"," 'training_epochs': 4,\n"," 'epoch': 4,\n"," 'training_loss': 0.5016463198560349,\n"," 'validation_loss': 0.5475732861086726,\n"," 'best_epoch': 4,\n"," 'best_validation_loss': 0.5475732861086726}"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"IACyJjdanNin"},"source":["## **Prediction**\n","\n","Lastly, we can also write the prediction class `PaperClassifierPredictor` which take input any `json_dict` and return the `Instance`. The AllenNLP will take care of the prediction."]},{"cell_type":"code","metadata":{"id":"HtIufo1xnNio"},"source":["from allennlp.common.util import JsonDict\n","from allennlp.predictors.predictor import Predictor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bxnf-xZWnNir"},"source":["class PaperClassifierPredictor(Predictor):\n","    \"\"\"\"\n","    Predictor wrapper for the AcademicPaperClassifier\n","    \"\"\"\n","    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n","        title = json_dict['title']\n","        abstract = json_dict['paperAbstract']\n","        instance = self._dataset_reader.text_to_instance(title=title, abstract=abstract)\n","        return instance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"whyyplq_nNiv"},"source":["predictor = PaperClassifierPredictor(model, dataset_reader=reader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWgOAMILnNiy","outputId":"b195e6e7-f802-43b6-ef15-723bdd14904f"},"source":["prediction_output = predictor.predict_json(\n","    {\n","        \"title\": \"Know What You Don't Know: Unanswerable Questions for SQuAD\", \n","        \"paperAbstract\": \"Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.\"\n","    }\n",")\n","\n","print(prediction_output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'logits': [1.7778292894363403, 0.11821205168962479, -1.8632274866104126], 'class_probabilities': [0.8220734000205994, 0.15636803209781647, 0.02155855856835842], 'predicted_label': 'ACL'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6WX3pxSpnNi1"},"source":["## **Load model for prediction**\n","\n","Here, we trained the model and save it in `output` folder using \n","\n","```\n","allennlp train example_training.json -s output --include-package venue\n","```\n","\n","`venue` is a library that we created where we make AllenNLP as a library. We can load trained model (`model.tar.gz`) from `serialization_dir` (`output`) and use it to predict the classes."]},{"cell_type":"code","metadata":{"id":"vl9jjj8BnNi1","outputId":"b5913f3a-489b-4312-8985-0d7567334b24"},"source":["from allennlp.models.archival import load_archive\n","from allennlp.predictors.predictor import Predictor\n","from venue.venue_predictor import PaperClassifierPredictor\n","from venue.venue_reader import PublicationDatasetReader\n","from venue.venue_classifier import AcademicPaperClassifier\n","\n","archive = load_archive('output/model.tar.gz')\n","venue_predictor = Predictor.from_archive(archive, 'venue_predictor')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/Users/titipata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9dl5JsRSnNi4","outputId":"db529058-c40d-4538-dc70-6ef104e4e7ae"},"source":["prediction_output = venue_predictor.predict_json(\n","    {\n","        \"title\": \"Know What You Don't Know: Unanswerable Questions for SQuAD\", \n","        \"paperAbstract\": \"Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.\"\n","    }\n",")\n","\n","print(prediction_output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'logits': [1.3005162477493286, 0.6157346367835999, -2.2390244007110596], 'class_probabilities': [0.6522191762924194, 0.3288491368293762, 0.018931740894913673], 'predicted_label': 'ACL'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-jEltplVnNi7","outputId":"4f89679b-fb9b-41a6-ed3f-25ba32b63546"},"source":["venue_predictor._model.vocab.get_index_to_token_vocabulary('labels') # all classes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'ACL', 1: 'AI', 2: 'ML'}"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"10Sn-VhYnNi-"},"source":["## **Predict which journals to submit from Medline**\n","\n","We  do a fun experiment where we train the same model to classify \n","publications from sample 110 journals from MEDLINE. We got accuracy of 64.9 percent on the validation dataset."]},{"cell_type":"code","metadata":{"id":"1GnvWctNnNi_"},"source":["import torch\n","from allennlp.models.archival import load_archive\n","from allennlp.predictors.predictor import Predictor\n","from venue.venue_predictor import PaperClassifierPredictor\n","from venue.venue_reader import PublicationDatasetReader\n","from venue.venue_classifier import AcademicPaperClassifier\n","from allennlp.common.file_utils import cached_path\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alWDqtU8nNjE","outputId":"bd23fb7c-3d1c-47c8-d223-189dab2ac27b"},"source":["archive = load_archive(cached_path('https://s3-us-west-2.amazonaws.com/allennlp-tutorial/model.tar.gz'))\n","venue_predictor = Predictor.from_archive(archive, 'venue_predictor')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/Users/titipata/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZgRLwAUonNjH"},"source":["title = \"\"\"\n","Modeling peripheral visual acuity enables discovery of gaze strategies \n","at multiple time scales during natural scene search\n","\"\"\"\n","abstract = \"\"\"\n","Like humans, monkeys make saccades nearly three times a second. \n","To understand the factors guiding this frequent decision, computational models of vision \n","attempt to predict fixation locations using bottom-up visual features and top-down goals. \n","How do the relative influences of these factors evolve over multiple time scales? \n","Here we analyzed visual features at fixations using a retinal transform that provides realistic \n","visual acuity by suitably degrading visual information in the periphery. \n","In a task in which monkeys searched for a Gabor target in natural scenes, we characterized \n","the relative importance of bottom-up and task-relevant influences by decoding fixated from \n","nonfixated image patches based on visual features. At fast time scales, we found that search \n","strategies can vary over the course of a single trial, with locations of higher saliency, target-similarity, \n","edge–energy, and orientedness looked at later on in the trial. At slow time scales, we found that \n","search strategies can be refined over several weeks of practice, and the influence of target orientation \n","was significant only in the latter of two search tasks. Critically, these results were not observed without \n","applying the retinal transform. Our results suggest that saccade-guidance strategies become apparent only \n","when models take into account degraded visual representation in the periphery.'\n","\"\"\"\n","prediction_output = venue_predictor.predict_json(\n","    {\n","        \"title\": title, \n","        \"paperAbstract\": abstract\n","    }\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDvzx0ycnNjK"},"source":["venues = venue_predictor._model.vocab.get_index_to_token_vocabulary('labels') # all classes\n","venues = [venues[i] for i in range(len(venues))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PA315SACnNjN","outputId":"eb514391-844c-4e62-a08c-81de575eabe6"},"source":["# rank top 5 which journal to submit\n","sorted(list(zip(venues, prediction_output['class_probabilities'])), \n","       key=lambda x: x[1], reverse=True)[0:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Journal of vision', 0.4988258183002472),\n"," ('Frontiers in psychology', 0.40092626214027405),\n"," ('Journal of neurophysiology', 0.048388607800006866),\n"," ('The Journal of neuroscience : the official journal of the Society for Neuroscience',\n","  0.03905167803168297),\n"," ('PLoS computational biology', 0.006291377358138561)]"]},"metadata":{"tags":[]},"execution_count":5}]}]}